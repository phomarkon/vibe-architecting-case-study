# Experiment Methodology

## Overview

Three customer service chatbot variants were generated independently by an AI coding agent, each from a single natural-language prompt. The goal was to observe how different prompt specifications produce architecturally divergent systems.

## Generation Tool

- **Orchestrator:** Claude Code CLI (claude-opus-4-6)
- **Generating agents:** Claude Code subagents (Claude Sonnet 4.5, model ID `claude-sonnet-4-5-20250929`)
- **Runtime LLM (in generated code):** OpenAI GPT-4o-mini (specified in each prompt to control for this variable)

## Date

February 11, 2026

## Procedure

1. The project's `CLAUDE.md` was temporarily renamed to `CLAUDE.md.hidden` to prevent subagents from ingesting project context that describes the expected architectures.
2. All prior experiment variants were moved to separate directories (`variant-{a,b,c}-handcrafted/`, `variant-{a,b,c}-contaminated/`) so subagents could not read them.
3. Three Claude Code subagents were launched **in parallel** using the Task tool with `run_in_background: true` and `subagent_type: claudeboyz-builder`.
4. Each subagent received **only** its generation prompt and boilerplate instructions (write to a specific directory, include package.json/README/.env.example, include a web UI, do not look at other files).
5. Each subagent wrote all files to its assigned directory (`variant-a/`, `variant-b/`, `variant-c/`).
6. After all three generations completed, `CLAUDE.md` was restored.
7. `PROMPT.md` files were added to each variant directory recording the exact prompts used.

## Independence Guarantee

- Each subagent was a fresh Claude Code subprocess with no shared context.
- The project's `CLAUDE.md` (which describes expected architectures and the paper's taxonomy) was hidden during generation.
- No subagent had access to the paper manuscript, the taxonomy of coupling patterns, or any prior variants.
- The only shared constraint was "Use OpenAI GPT-4o-mini as the LLM" to isolate prompt specification as the independent variable.
- Subagents were instructed "Do NOT look at any other files in this repository."

## Post-Generation Edits

- `better-sqlite3` in variant-c was upgraded from `^9.4.0` to `^12.6.2` because the agent-pinned version did not compile on Node.js v25.4.0. This is an environment compatibility fix; no source code was changed.
- `PROMPT.md` files were added to each variant directory (not part of generated code).
- `ARCHITECTURE.md`, `README.md`, and other documentation files in each variant were generated by the agent. These docs contain references to other variants and the paper taxonomy that the agent inferred from directory structure or its training data. The source code files contain no such references.

## Prompts Used

### Variant A (FAQ chatbot)
> Build a Node.js/Express customer service chatbot that answers product questions using a FAQ list. Keep it simple. Use OpenAI GPT-4o-mini as the LLM.

### Variant B (Structured JSON output)
> Build a Node.js/Express customer service chatbot that analyzes customer messages and returns structured JSON with intent, confidence, entities, and a response. Use schema validation for the LLM output. Use OpenAI GPT-4o-mini as the LLM.

### Variant C (Tool-using agent)
> Build a Node.js/Express customer service chatbot that acts as an agent with tool access: search_kb() for knowledge base search, get_account() for customer account lookup, and escalate_to_human() for escalation. The agent should decide which tools to call based on the conversation. Use OpenAI GPT-4o-mini as the LLM.

## Observed Results

| Dimension | Variant A | Variant B | Variant C |
|---|---|---|---|
| **Source files** | 4 | 4 (`src/`) | 7 (`src/`, `src/tools/`, `src/state/`) |
| **Dependencies** | 3 (express, openai, dotenv) | 4 (+ zod) | 4 (+ better-sqlite3) |
| **Module system** | ESM (`import`) | ESM (`import`) | ESM (`import`) |
| **Project structure** | Flat (root-level .js) | `src/` directory | `src/` with `tools/` and `state/` subdirs |
| **LLM integration** | Single API call, free-form text | JSON mode + Zod validation | Function calling with agent loop |
| **Validation** | None | Zod schema + JSON mode | Tool argument parsing via JSON.parse |
| **Error recovery** | try/catch only | Exponential backoff retry (3 attempts) | Max iteration guard (10 iterations) |
| **State management** | None (stateless) | None (stateless) | SQLite (server-side conversation history) |
| **Key architectural pattern** | Context injection | Pipe-and-filter (validate -> retry -> fallback) | Agent loop (observe -> decide -> act -> observe) |

## Threats to Validity

1. **Prompt prescriptiveness.** The prompts themselves encode architectural expectations (e.g., "schema validation" implies a validation layer; "tool access" implies orchestration). The experiment demonstrates that prompt-level decisions drive architectural outcomes, not that vague prompts produce divergent architectures spontaneously.
2. **Single generation per prompt.** Each prompt was run once. Variance across multiple runs of the same prompt was not measured.
3. **Agent-generated documentation.** The `ARCHITECTURE.md` files generated by the agents contain references to other variants and the paper's taxonomy, suggesting the agents inferred context from directory names or training data. The source code itself contains no such contamination.
4. **Same generating tool.** All variants were generated by the same tool (Claude Code with Sonnet 4.5 subagents). Different tools (Cursor, Devin) might produce different architectures for the same prompts.
